{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG5BPplwYIch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_6L375OivDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_dir = \"gdrive/My Drive/Colab Notebooks/gatys/\"\n",
        "model_dir = project_dir\n",
        "style_dir = project_dir + \"style_images/\"\n",
        "content_dir = project_dir + \"content_images/\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OeddrU2Zdh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "691237be-8e0e-4e0b-f0a2-7736223e468f"
      },
      "source": [
        "USE_GPU = False\n",
        "dtype = torch.float32\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI3VFNrlbXLG",
        "colab_type": "text"
      },
      "source": [
        "The architecture used by Gatys et al. is a subset of VGG-19. Namely, 5 \"convolutional layers\" (each of which is really a \"sandwiching\" of consecutive convolutional-relu pairs) joined by a pooling layer. The authors note that better performance was achieved with average pooling, compared to max pooling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVzRfNm9chsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, content_acts, style_acts):\n",
        "        super().__init__()\n",
        "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, padding=1, kernel_size=3)\n",
        "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, padding=1, kernel_size=3)\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, padding=1, kernel_size=3)\n",
        "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, padding=1, kernel_size=3)\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, padding=1, kernel_size=3)\n",
        "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, padding=1, kernel_size=3)\n",
        "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, padding=1, kernel_size=3)\n",
        "        self.conv3_4 = nn.Conv2d(in_channels=256, out_channels=256, padding=1, kernel_size=3)\n",
        "        self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv4_4 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "        self.conv5_4 = nn.Conv2d(in_channels=512, out_channels=512, padding=1, kernel_size=3)\n",
        "\n",
        "        self.content_acts = content_acts\n",
        "        self.style_acts = style_acts\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = {}  # cache all layers from forward pass\n",
        "\n",
        "        out[\"r11\"] = F.relu(self.conv1_1(x))\n",
        "        out[\"r12\"] = F.relu(self.conv1_2(out[\"r11\"]))\n",
        "        out[\"p1\"] = self.pool1(out[\"r12\"])  # note pooling is done to preserve shape\n",
        "\n",
        "        out[\"r21\"] = F.relu(self.conv2_1(out[\"p1\"]))\n",
        "        out[\"r22\"] = F.relu(self.conv2_2(out[\"r21\"]))\n",
        "        out[\"p2\"] = self.pool2(out[\"r22\"])\n",
        "\n",
        "        out[\"r31\"] = F.relu(self.conv3_1(out[\"p2\"]))\n",
        "        out[\"r32\"] = F.relu(self.conv3_1(out[\"r31\"]))\n",
        "        out[\"r33\"] = F.relu(self.conv3_1(out[\"r32\"]))\n",
        "        out[\"r34\"] = F.relu(self.conv3_1(out[\"r33\"]))\n",
        "        out[\"p3\"] = self.pool3(out[\"r34\"])\n",
        "\n",
        "        out[\"r41\"] = F.relu(self.conv4_1(out[\"p3\"]))\n",
        "        out[\"r42\"] = F.relu(self.conv4_1(out[\"r41\"]))\n",
        "        out[\"r43\"] = F.relu(self.conv4_1(out[\"r42\"]))\n",
        "        out[\"r44\"] = F.relu(self.conv4_1(out[\"r43\"]))\n",
        "        out[\"p4\"] = self.pool3(out[\"r44\"])\n",
        "\n",
        "        out[\"r51\"] = F.relu(self.conv3_1(out[\"p4\"]))\n",
        "        out[\"r52\"] = F.relu(self.conv3_1(out[\"r51\"]))\n",
        "        out[\"r53\"] = F.relu(self.conv3_1(out[\"r52\"]))\n",
        "        out[\"r54\"] = F.relu(self.conv3_1(out[\"r53\"]))\n",
        "\n",
        "        return out\n",
        "    \n",
        "    def get_activations(self, out, mode):\n",
        "        if mode == \"content\":\n",
        "            return [out[layer] for layer in self.content_acts]\n",
        "        elif mode == \"style\":\n",
        "            return [out[layer] for layer in self.style_acts]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw9jMl9vSQEJ",
        "colab_type": "text"
      },
      "source": [
        "TODO: Explain style content functions below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpaGucBdnR4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(feature_maps):\n",
        "    N, C, H, W = feature_maps.shape\n",
        "    flat = feature_maps.reshape(N, C, H*W)\n",
        "    flat_t = flat.permute(0, 2, 1)\n",
        "    gram = torch.bmm(flat, flat_t)\n",
        "    gram.div_(H * W)  # normalize by image size\n",
        "    return gram\n",
        "\n",
        "def style_loss(gen_grams, orig_grams):\n",
        "    batch_size = len(gen_grams)\n",
        "    return F.mse_loss(gen_grams, orig_grams) / batch_size"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaZ6S7aASXqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 512  # see section 4 of paper\n",
        "BGR_means = [0.40760392, 0.45795686, 0.48501961]\n",
        "\n",
        "pre = T.Compose([\n",
        "    T.Resize(image_size),\n",
        "    T.ToTensor(),\n",
        "    T.Lambda(lambda x: x[torch.LongTensor([2,1,0])]),\n",
        "    T.Normalize(mean=BGR_means, std=[1,1,1]),\n",
        "    T.Lambda(lambda x : x.mul_(255.)),\n",
        "])\n",
        "\n",
        "post = T.Compose([\n",
        "    T.Lambda(lambda x : x.div_(255.)),\n",
        "    T.Normalize(mean=[-i for i in BGR_means], std=[1,1,1]),\n",
        "    T.Lambda(lambda x: x[torch.LongTensor([2,1,0])]),\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdI65F58FAuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b91f887d-a532-4247-e59c-11e8ca05b8b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ZT4r0jkLu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "cbc66b38-9457-4ece-91ec-512ebcbb284a"
      },
      "source": [
        "# load images\n",
        "style_img = Image.open(style_dir + \"vasjen_katro.png\").convert(\"RGB\")\n",
        "content_img = Image.open(content_dir + \"gits.jpg\").convert(\"RGB\")\n",
        "images = (style_img, content_img)\n",
        "\n",
        "plt.imshow(np.asarray(style_img))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(np.asarray(content_img))\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e02348790712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstyle_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"vasjen_katro.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcontent_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"gits.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstyle_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/My Drive/Colab Notebooks/gatys/style_images/vasjen_katro.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0AayrexDrsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84fb70a4-942e-43ab-ab3a-4aa62133c4c9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'style_dir': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAr9ale5Dyd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7bfbe9c4-30b2-482d-bf74-9570953907b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbgr-G3p4Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-process images\n",
        "imgs_torch = [pre(img) for img in images]\n",
        "if USE_GPU:\n",
        "    imgs_torch = [img.unsqueeze(0).cuda() for img in imgs_torch]\n",
        "else:\n",
        "    imgs_torch = [img.unsqueeze(0) for img in imgs_torch]\n",
        "\n",
        "# unpack processed images\n",
        "style_img, content_img = imgs_torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyhaD5WKcp8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get network\n",
        "vgg = VGG()\n",
        "vgg.load_state_dict(torch.load(model_dir + 'vgg_conv.pth'))\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "if torch.cuda.is_available():\n",
        "    vgg.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgRpuYxjy-al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw5aY1wC0djJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a7aed99-25ef-4722-a3f6-70a1c74aab98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNz6ZRL0y8b_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBqhBGCeovGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c459f1c-7e61-4cd0-af96-e33f41c7cdac"
      },
      "source": [
        "a = torch.arange(16).reshape(2,2,2,2)\n",
        "\n",
        "a = a.reshape(2, 2, 4)\n",
        "b = a.permute(0, 2, 1)\n",
        "ab = torch.bmm(a, b)\n",
        "print(ab.shape)\n",
        "print(np.prod((ab.shape)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 2])\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPnnFjUAsCeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2c73b81-ff7a-44fc-9a63-14e178b919ee"
      },
      "source": [
        "a = torch.arange(8, dtype=dtype).reshape(2,2,2)\n",
        "b = torch.arange(8, 16, dtype=dtype).reshape(2,2,2)\n",
        "F.mse_loss(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(64.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iuMb9KiwK_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "65a4aa43-1bce-45ff-d9c9-4388dd41c4cf"
      },
      "source": [
        "a = torch.arange(60, dtype=dtype).reshape(3,4,5)\n",
        "foo = T.Compose([\n",
        "    #T.Lambda(lambda x : x.div_(2.)),\n",
        "    #T.Normalize(mean=BGR_means, std=[1,1,1]),\n",
        "    T.Lambda(lambda x : x.T)\n",
        "])\n",
        "\n",
        "bar = T.Compose([\n",
        "    T.Lambda(lambda x: x[torch.LongTensor([2,1,0])]),\n",
        "])\n",
        "print(a)\n",
        "print(foo(a))\n",
        "print(bar(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.,  9.],\n",
            "         [10., 11., 12., 13., 14.],\n",
            "         [15., 16., 17., 18., 19.]],\n",
            "\n",
            "        [[20., 21., 22., 23., 24.],\n",
            "         [25., 26., 27., 28., 29.],\n",
            "         [30., 31., 32., 33., 34.],\n",
            "         [35., 36., 37., 38., 39.]],\n",
            "\n",
            "        [[40., 41., 42., 43., 44.],\n",
            "         [45., 46., 47., 48., 49.],\n",
            "         [50., 51., 52., 53., 54.],\n",
            "         [55., 56., 57., 58., 59.]]])\n",
            "tensor([[[ 0., 20., 40.],\n",
            "         [ 5., 25., 45.],\n",
            "         [10., 30., 50.],\n",
            "         [15., 35., 55.]],\n",
            "\n",
            "        [[ 1., 21., 41.],\n",
            "         [ 6., 26., 46.],\n",
            "         [11., 31., 51.],\n",
            "         [16., 36., 56.]],\n",
            "\n",
            "        [[ 2., 22., 42.],\n",
            "         [ 7., 27., 47.],\n",
            "         [12., 32., 52.],\n",
            "         [17., 37., 57.]],\n",
            "\n",
            "        [[ 3., 23., 43.],\n",
            "         [ 8., 28., 48.],\n",
            "         [13., 33., 53.],\n",
            "         [18., 38., 58.]],\n",
            "\n",
            "        [[ 4., 24., 44.],\n",
            "         [ 9., 29., 49.],\n",
            "         [14., 34., 54.],\n",
            "         [19., 39., 59.]]])\n",
            "tensor([[[40., 41., 42., 43., 44.],\n",
            "         [45., 46., 47., 48., 49.],\n",
            "         [50., 51., 52., 53., 54.],\n",
            "         [55., 56., 57., 58., 59.]],\n",
            "\n",
            "        [[20., 21., 22., 23., 24.],\n",
            "         [25., 26., 27., 28., 29.],\n",
            "         [30., 31., 32., 33., 34.],\n",
            "         [35., 36., 37., 38., 39.]],\n",
            "\n",
            "        [[ 0.,  1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.,  9.],\n",
            "         [10., 11., 12., 13., 14.],\n",
            "         [15., 16., 17., 18., 19.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moghXyLycSjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}